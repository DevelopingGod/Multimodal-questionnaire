{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8b4_SDHx9tzN"
      },
      "outputs": [],
      "source": [
        "# Importing our libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. SETUP\n",
        "os.makedirs(\"models\", exist_ok=True)"
      ],
      "metadata": {
        "id": "4g8pLiKY689g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LOAD DATA (Prioritize the Cleaned \"No Sleep\" File)\n",
        "if os.path.exists(\"final_dataset_no_sleep.csv\"):\n",
        "    print(\"✅ Loading pre-cleaned dataset: 'final_dataset_no_sleep.csv'\")\n",
        "    df = pd.read_csv(\"final_dataset_no_sleep.csv\")\n",
        "\n",
        "    # Since the file is already cleaned, we just take all Q columns\n",
        "    feature_cols = [c for c in df.columns if \"Q\" in c]\n",
        "\n",
        "else:\n",
        "    # Fallback: Load original/corrected and clean in-memory\n",
        "    filename = \"corrected_mental_health_dataset.csv\"\n",
        "    if not os.path.exists(filename):\n",
        "        filename = \"synthetic_college_mental_health_dataset_v3_with_severity.csv\"\n",
        "        print(f\"⚠️ Clean file not found. Using '{filename}' and cleaning in-memory.\")\n",
        "    else:\n",
        "        print(f\"⚠️ Clean file not found. Using '{filename}' and cleaning in-memory.\")\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # A. Apply Clinical Hierarchy (Safety Check)\n",
        "    overlap_mask = (df['ASD_risk'] == 1) & (df['SPCD_risk'] == 1)\n",
        "    df.loc[overlap_mask, 'SPCD_risk'] = 0\n",
        "\n",
        "    # B. REMOVE SLEEP QUESTIONS (Madam's Requirement)\n",
        "    all_q_cols = [c for c in df.columns if \"Q\" in c]\n",
        "    # Filter out any column containing \"CONF\"\n",
        "    feature_cols = [c for c in all_q_cols if \"CONF\" not in c]\n",
        "\n",
        "print(f\"Training on {len(feature_cols)} features (27 Expected).\")\n",
        "\n",
        "risk_cols = [\"ADHD_risk\", \"ASD_risk\", \"SPCD_risk\", \"DEP_risk\", \"ANX_risk\"]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[risk_cols]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1SeSwU_7ABy",
        "outputId": "0067cd7a-30fd-4701-dc6e-d84b617ae0a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loading pre-cleaned dataset: 'final_dataset_no_sleep.csv'\n",
            "Training on 27 features (27 Expected).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. SPLIT DATA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save Test Data for the Report Generator\n",
        "pickle.dump((X_test, y_test), open(\"models/test_data.pkl\", \"wb\"))\n",
        "print(\"Saved 'models/test_data.pkl' for graph generation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEKtuqjw7DXM",
        "outputId": "2bb46aa1-a83b-4171-a4ad-419246879112"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 'models/test_data.pkl' for graph generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TRAIN ALL 4 RISK MODELS\n",
        "models = {\n",
        "    \"RF\": MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    # Removed use_label_encoder=False to fix UserWarning\n",
        "    \"XGB\": MultiOutputClassifier(xgb.XGBClassifier(eval_metric='logloss', random_state=42)),\n",
        "    \"SVM\": MultiOutputClassifier(SVC(kernel='linear', probability=True, random_state=42)),\n",
        "    \"KNN\": MultiOutputClassifier(KNeighborsClassifier(n_neighbors=5))\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name} Risk Model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    pickle.dump(model, open(f\"models/{name}_risk.pkl\", \"wb\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5sR0Oqb7GEI",
        "outputId": "4abd5f22-19c9-4f49-e053-6c17ee138a56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RF Risk Model...\n",
            "Training XGB Risk Model...\n",
            "Training SVM Risk Model...\n",
            "Training KNN Risk Model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. TRAIN SEVERITY MODELS (Random Forest)\n",
        "SEVERITY_MAPPING = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "severity_map_cols = {\n",
        "    \"ADHD\": \"ADHD_severity\", \"ASD\": \"ASD_severity\", \"SPCD\": \"SPCD_severity\",\n",
        "    \"DEP\": \"DEP_severity\", \"ANX\": \"ANX_severity\"\n",
        "}\n",
        "\n",
        "print(\"\\nTraining Severity Models (RF)...\")\n",
        "for disorder, sev_col in severity_map_cols.items():\n",
        "    risk_col = f\"{disorder}_risk\"\n",
        "\n",
        "    # Train only on rows where the disorder exists\n",
        "    sev_df = df[df[risk_col] == 1].copy()\n",
        "\n",
        "    X_sev = sev_df[feature_cols] # 27 cols\n",
        "    y_sev = sev_df[sev_col].map(SEVERITY_MAPPING).fillna(0)\n",
        "\n",
        "    rf_sev = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=42)\n",
        "    rf_sev.fit(X_sev, y_sev)\n",
        "    pickle.dump(rf_sev, open(f\"models/rf_{disorder}_sev.pkl\", \"wb\"))\n",
        "\n",
        "print(\"\\n✅ All models retrained successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am6iF2DF7IeM",
        "outputId": "b613d4d3-43e4-4168-ee98-925f3e26d61e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Severity Models (RF)...\n",
            "\n",
            "✅ All models retrained successfully!\n"
          ]
        }
      ]
    }
  ]
}